{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pachterlab/gget_examples/blob/main/gget_virus/gget_virus_colab_interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4vLF8GBtT_"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <h1 style=\"font-size: 2.5em; color: #2C3E50;\">Running <a href=\"https://github.com/pachterlab/gget_examples\" target=\"_blank\">Delphy</a> is as simple as 1, 2, 3</h1>\n",
        "    <h2 style=\"font-size: 1.5em; color: #34495E;\">Phylogenetic Tree Generation with Delphy</h2>\n",
        "</div>\n",
        "\n",
        "This notebook demonstrates how to generate a phylogenetic tree using [Delphy](https://github.com/broadinstitute/delphy) on viral sequences obtained from the [NCBI Virus Database](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/). Optionally, you can also upload your own sequences to be included in the analysis.\n",
        "\n",
        "We will utilize the following tools:\n",
        "- [**gget**](https://pachterlab.github.io/gget/en/virus.html) to download sequences from the [NCBI Virus Database](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/)\n",
        "- [**MAFFT**](https://mafft.cbrc.jp/alignment/server/index.html) for creating a Multiple-Sequence Alignment (MSA)\n",
        "- [**Delphy**](https://github.com/broadinstitute/delphy) to generate the phylogenetic tree\n",
        "\n",
        "If you encounter any problems or questions while using this notebook, please [report them here](https://github.com/broadinstitute/delphy/issues).\n",
        "\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Apply filters to download sequences from [NCBI Virus](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/)"
      ],
      "metadata": {
        "id": "sWOSpHI-iGVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title gget virus filtering options:\n",
        "#@markdown Set any non-boolean filter to `None` to disable it.\n",
        "\n",
        "def arg_str_to_bool(arg):\n",
        "    if arg == \"True\":\n",
        "        return True\n",
        "    elif arg == \"False\":\n",
        "        return False\n",
        "    elif arg == \"None\" or arg == \"\":\n",
        "        return None\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "# -------------------------\n",
        "# Virus query\n",
        "# -------------------------\n",
        "#@markdown ## **Virus**\n",
        "\n",
        "virus = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Examples: 'Mammarenavirus lassaense' or 'coronaviridae' or 'NC_045512.2' or '142786' (Norovirus taxid).\n",
        "virus = arg_str_to_bool(virus)\n",
        "\n",
        "is_accession = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Check this box if `virus` is given as an NCBI accession (starts with 'NC_').\n",
        "#@markdown  - For SARS-CoV-2 / Influenza A optimized downloads also check the corresponding box below (see `is_sars_cov2` / `is_alphainfluenza` below)\n",
        "is_accession = arg_str_to_bool(is_accession)\n",
        "\n",
        "download_all_accessions = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - ‚ö†Ô∏è Downloads ALL virus accessions from NCBI (very large database).\n",
        "download_all_accessions = arg_str_to_bool(download_all_accessions)\n",
        "\n",
        "# -------------------------\n",
        "# Host filters\n",
        "# -------------------------\n",
        "#@markdown ## **Host**\n",
        "\n",
        "host = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Host organism name OR NCBI Taxonomy ID (e.g., 'human', 'Aedes aegypti', '1335626').\n",
        "#@markdown  - Input 'None' to disable filtering by host.\n",
        "host = arg_str_to_bool(host)\n",
        "\n",
        "# -------------------------\n",
        "# Sequence & gene filters\n",
        "# -------------------------\n",
        "#@markdown ## **Sequence & gene filters**\n",
        "\n",
        "annotated = \"None\"  #@param [\"True\", \"False\", \"None\"]\n",
        "#@markdown  - True: only annotated sequences. False: only NOT annotated. None: no filter.\n",
        "annotated = arg_str_to_bool(annotated)\n",
        "\n",
        "refseq_only = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Limit search to RefSeq genomes only (curated).\n",
        "refseq_only = arg_str_to_bool(refseq_only)\n",
        "\n",
        "nuc_completeness = \"None\"  #@param [\"None\", \"complete\", \"partial\"]\n",
        "#@markdown  - Set to 'complete' to only return nucleotide sequences marked as complete; set to 'partial' to only return sequences that are marked as partial.\n",
        "nuc_completeness = arg_str_to_bool(nuc_completeness)\n",
        "\n",
        "min_seq_length = None  #@param {type:\"raw\"}\n",
        "max_seq_length = None  #@param {type:\"raw\"}\n",
        "\n",
        "min_seq_length = arg_str_to_bool(min_seq_length)\n",
        "max_seq_length = arg_str_to_bool(max_seq_length)\n",
        "\n",
        "#@markdown\n",
        "max_ambiguous_chars = None  #@param {type:\"raw\"}\n",
        "#@markdown  - Max number of ambiguous nucleotide characters (N's).\n",
        "max_ambiguous_chars = arg_str_to_bool(max_ambiguous_chars)\n",
        "\n",
        "min_gene_count = None  #@param {type:\"raw\"}\n",
        "max_gene_count = None  #@param {type:\"raw\"}\n",
        "#@markdown\n",
        "min_gene_count = arg_str_to_bool(min_gene_count)\n",
        "max_gene_count = arg_str_to_bool(max_gene_count)\n",
        "#@markdown\n",
        "min_protein_count = None  #@param {type:\"raw\"}\n",
        "max_protein_count = None  #@param {type:\"raw\"}\n",
        "#@markdown\n",
        "min_protein_count = arg_str_to_bool(min_protein_count)\n",
        "max_protein_count = arg_str_to_bool(max_protein_count)\n",
        "#@markdown\n",
        "min_mature_peptide_count = None  #@param {type:\"raw\"}\n",
        "max_mature_peptide_count = None  #@param {type:\"raw\"}\n",
        "#@markdown\n",
        "min_mature_peptide_count = arg_str_to_bool(min_mature_peptide_count)\n",
        "max_mature_peptide_count = arg_str_to_bool(max_mature_peptide_count)\n",
        "\n",
        "has_proteins = None  #@param {type:\"raw\"}\n",
        "#@markdown  - Require specific proteins/genes (e.g. \"spike\") or list (e.g. [\"spike\",\"ORF1ab\"]). **Include quotation marks.**\n",
        "has_proteins = arg_str_to_bool(has_proteins)\n",
        "\n",
        "proteins_complete = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Only include sequences where all annotated proteins are complete.\n",
        "proteins_complete = arg_str_to_bool(proteins_complete)\n",
        "\n",
        "# -------------------------\n",
        "# Location & submitter filters\n",
        "# -------------------------\n",
        "#@markdown ## **Location & submitter filters**\n",
        "\n",
        "geographic_location = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Geographic location of sample collection (e.g. 'USA', 'Asia').\n",
        "geographic_location = arg_str_to_bool(geographic_location)\n",
        "\n",
        "submitter_country = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Country of the sequence submitter.\n",
        "submitter_country = arg_str_to_bool(submitter_country)\n",
        "\n",
        "lab_passaged = \"None\"  #@param [\"True\", \"False\", \"None\"]\n",
        "#@markdown  - True: only lab-passaged. False: exclude lab-passaged. None: no filter.\n",
        "lab_passaged = arg_str_to_bool(lab_passaged)\n",
        "\n",
        "# -------------------------\n",
        "# Date filters\n",
        "# -------------------------\n",
        "#@markdown ## **Dates**\n",
        "#@markdown All dates should be supplied in YYYY-MM-DD format.\n",
        "\n",
        "min_collection_date = \"\"  #@param {type:\"string\"}\n",
        "max_collection_date = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "min_release_date = \"\"  #@param {type:\"string\"}\n",
        "max_release_date = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "min_collection_date = arg_str_to_bool(min_collection_date)\n",
        "max_collection_date = arg_str_to_bool(max_collection_date)\n",
        "\n",
        "min_release_date = arg_str_to_bool(min_release_date)\n",
        "max_release_date = arg_str_to_bool(max_release_date)\n",
        "\n",
        "# -------------------------\n",
        "# SARS-CoV-2 specific filters / optimizations\n",
        "# -------------------------\n",
        "#@markdown ## **SARS-CoV-2 / Influenza A optimizations**\n",
        "\n",
        "lineage = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - SARS-CoV-2 lineage filter (e.g. 'B.1.1.7'). (Only meaningful for SARS-CoV-2 queries.)\n",
        "lineage = arg_str_to_bool(lineage)\n",
        "\n",
        "is_sars_cov2 = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Use optimized cached downloads for SARS-CoV-2.\n",
        "is_sars_cov2 = arg_str_to_bool(is_sars_cov2)\n",
        "\n",
        "is_alphainfluenza = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Use optimized cached downloads for Influenza A virus (Alphainfluenza).\n",
        "is_alphainfluenza = arg_str_to_bool(is_alphainfluenza)\n",
        "\n",
        "# -------------------------\n",
        "# Optional GenBank metadata enrichment\n",
        "# -------------------------\n",
        "#@markdown ## **GenBank metadata enrichment**\n",
        "\n",
        "genbank_metadata = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Fetch additional detailed metadata from GenBank into a separate CSV/XML/CSV dumps.\n",
        "genbank_metadata = arg_str_to_bool(genbank_metadata)\n",
        "\n",
        "genbank_batch_size = 200  #@param {type:\"integer\"}\n",
        "#@markdown  - Batch size for GenBank metadata API requests. Larger may be faster but can time out (default: 200).\n",
        "genbank_batch_size = int(genbank_batch_size)\n",
        "\n",
        "# -------------------------\n",
        "# Workflow / output options\n",
        "# -------------------------\n",
        "#@markdown ## **Workflow / output options**\n",
        "\n",
        "keep_temp = False  #@param {type:\"boolean\"}\n",
        "#@markdown  - Keep intermediate temporary files.\n",
        "keep_temp = arg_str_to_bool(keep_temp)\n",
        "\n",
        "outfolder = \"results\"  #@param {type:\"string\"}\n",
        "#@markdown  - Output folder path.\n",
        "outfolder = arg_str_to_bool(outfolder)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6cazzIZfiJDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Optional: Upload a fasta file with your own sequences to add to the analysis\n",
        "  **1) Click on the folder icon on the left.  \n",
        "  2) Upload your file to the Google Colab server by dragging in your file (or use rightclick -> Upload).  \n",
        "  3) Specify the name of your file here:**"
      ],
      "metadata": {
        "id": "aE8ot-AyiPdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FASTA file containing additional sequences\n",
        "\n",
        "fasta_file = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Example: 'my_fasta_file.fa' or 'my_fasta_file.fasta'.\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E-lg25zave0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Metadata\n",
        "\n",
        "#@markdown **Option 1: The metadata is the same for all sequences in your FASTA file**\n",
        "metadata = {'Collection Date': 'YYYY-MM-DD', 'Geo Location': 'South Korea'}  #@param {type:\"raw\"}\n",
        "#@markdown - The 'Collection Date' field is required. Optional: you can add as many additional columns as you wish, e.g. 'Geo Location': 'South Korea'.\n",
        "#@markdown - NOTE: Use NCBI column names where applicable (see https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus for example column names)\n",
        "\n",
        "#@markdown **Option 2: Input a CSV file with metadata for each sequence**\n",
        "metadata_csv = \"\"  #@param {type:\"string\"}\n",
        "#@markdown  - Example: 'my_metadata.csv'. This file must include at least an 'Accession' and 'Collection Date' column.\n",
        "#@markdown  - NOTE: Make sure the IDs in the \"Accession\" column match the IDs of the sequences in the provided FASTA file\n",
        "#@markdown  - NOTE: Use NCBI column names where applicable (see https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus for example column names)\n",
        "\n",
        "# Convert empty strings to None\n",
        "fasta_file = arg_str_to_bool(fasta_file)\n",
        "metadata_csv = arg_str_to_bool(metadata_csv)"
      ],
      "metadata": {
        "id": "LKgxMFBgiP64",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Optional: Specify Delphy arguments"
      ],
      "metadata": {
        "id": "zQF5zZ2dzS60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delphy options:\n",
        "\n",
        "mutation_rate = None  #@param {type:\"raw\"}\n",
        "#@markdown  - Virus mutation rate (mutations per site per year), e.g. 0.01. If set to `None`, the mutation rate will be estimated from the generated tree.\n",
        "\n",
        "delphy_steps = None  #@param {type:\"raw\"}\n",
        "#@markdown  - Number of steps to run in the Delphy algorithm (default: 500,000 * number of sequences).\n",
        "\n",
        "delphy_samples = 200 #@param {type:\"integer\"}\n",
        "#@markdown  - Number of logging and tree updates (will log every `delphy_steps/delphy_samples` step).\n",
        "\n",
        "delphy_release = \"1.2.2\"  #@param {type:\"string\"}\n",
        "#@markdown  - Delphy version to use (see https://github.com/broadinstitute/delphy/releases).\n",
        "\n",
        "#@title Delphy options:\n",
        "threads = 2  #@param {type:\"integer\"}\n",
        "#@markdown  - Number of threads to use for the MSA (Mafft) and phylogenetic tree (Delphy) generation."
      ],
      "metadata": {
        "cellView": "form",
        "id": "bEM5nlzZzSih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select `Runtime` at the top of this notebook, then click `Run all` and lean back...\n",
        "A completion message will be displayed below once the notebook has been successfully executed.  \n",
        "**üí° Tip: Click on the folder icon üìÅ on the left to view/download the files that are being generated.**\n",
        "  \n",
        "<br>\n",
        "\n",
        "____\n",
        "____\n",
        "____\n",
        "____"
      ],
      "metadata": {
        "id": "UTL55NF2jAj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#@title # Generating the phylogenetic tree...\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------- Small UI helpers ----------\n",
        "def log_message(text):\n",
        "    display(HTML(f\"<h3 style='color:green;margin:6px 0'>{text}</h3>\"))\n",
        "\n",
        "def log_message_sub(text):\n",
        "    display(HTML(f\"<p style='color:black; font-weight:normal; margin:4px 0;'>{text}</p>\"))\n",
        "\n",
        "def log_message_error(text):\n",
        "    display(HTML(f\"<h3 style='color:red;margin:6px 0'>{text}</h3>\"))\n",
        "\n",
        "def run_checked(cmd, **kwargs):\n",
        "    \"\"\"Run subprocess.run with sensible defaults and return CompletedProcess or raise.\"\"\"\n",
        "    default = dict(check=True, text=True, capture_output=True)\n",
        "    default.update(kwargs)\n",
        "    return subprocess.run(cmd, **default)\n",
        "\n",
        "# ---------- Validate / create outfolder ----------\n",
        "outfolder = Path(outfolder) if 'outfolder' in globals() else Path(\"delphy_out\")\n",
        "outfolder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- 1) Install Python requirements (gget) ----------\n",
        "log_message(\"1/5 Installing Python dependencies (gget)...\")\n",
        "try:\n",
        "    !pip install --upgrade -q gget biopython\n",
        "    import gget\n",
        "    from Bio import SeqIO\n",
        "    log_message_sub(\"Python dependencies installed.\")\n",
        "except Exception as e:\n",
        "    log_message_error(\"Failed to install Python dependencies (gget).\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# ---------- 2) Download sequences from NCBI using gget ----------\n",
        "log_message(\"2/5 Downloading viral sequences from NCBI (gget.virus)... This may take a few minutes.\")\n",
        "try:\n",
        "    # The original code used many parameters assumed present in the notebook; call gget.virus with locals()\n",
        "    # Build kwargs only from variables that exist in globals() and are not None.\n",
        "    possible_kwargs = [\n",
        "        \"virus\",\"is_accession\",\"download_all_accessions\",\"host\",\n",
        "        \"nuc_completeness\",\"min_seq_length\",\"max_seq_length\",\n",
        "        \"min_gene_count\",\"max_gene_count\",\"min_mature_peptide_count\",\"max_mature_peptide_count\",\n",
        "        \"min_protein_count\",\"max_protein_count\",\"max_ambiguous_chars\",\"has_proteins\",\"proteins_complete\",\"annotated\",\"refseq_only\",\n",
        "        \"geographic_location\",\"submitter_country\",\"lab_passaged\",\n",
        "        \"min_collection_date\",\"max_collection_date\",\"min_release_date\",\"max_release_date\",\n",
        "        \"lineage\",\"is_sars_cov2\",\"is_alphainfluenza\",\n",
        "        \"genbank_metadata\",\"genbank_batch_size\",\"keep_temp\",\"outfolder\"\n",
        "    ]\n",
        "    gget_kwargs = {k: globals()[k] for k in possible_kwargs if k in globals() and globals()[k] is not None}\n",
        "    # Ensure outfolder is string path for gget\n",
        "    if \"outfolder\" not in gget_kwargs:\n",
        "        gget_kwargs[\"outfolder\"] = str(outfolder)\n",
        "    else:\n",
        "        gget_kwargs[\"outfolder\"] = str(Path(gget_kwargs[\"outfolder\"]))\n",
        "    # Call gget.virus\n",
        "    gget.virus(**gget_kwargs)\n",
        "\n",
        "    # Find the newest fasta and metadata file in outfolder\n",
        "    fasta_candidates = list(outfolder.glob(\"*.fasta\")) + list(outfolder.glob(\"*.fa\"))\n",
        "    if not fasta_candidates:\n",
        "        raise FileNotFoundError(f\"No fasta files were created in {outfolder}\")\n",
        "    ncbi_fasta_file = max(fasta_candidates, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "    metadata_candidates = list(outfolder.glob(\"*.csv\")) + list(outfolder.glob(\"*.jsonl\")) + list(outfolder.glob(\"*.tsv\"))\n",
        "    if not metadata_candidates:\n",
        "        raise FileNotFoundError(f\"No metadata files were created in {outfolder}\")\n",
        "    ncbi_metadata = max(metadata_candidates, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "    log_message_sub(f\"Download complete. FASTA: {ncbi_fasta_file.name}  Metadata: {ncbi_metadata.name}\")\n",
        "except Exception as e:\n",
        "    log_message_error(\"Error while downloading sequences from NCBI.\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# ---------- 2b) If user provided FASTA/metadata, merge them ----------\n",
        "input_fasta_file = Path(ncbi_fasta_file)\n",
        "metadata_file = Path(ncbi_metadata)\n",
        "\n",
        "if 'fasta_file' in globals() and fasta_file:\n",
        "    log_message_sub(\"Merging user-provided FASTA with NCBI FASTA...\")\n",
        "    try:\n",
        "        combined_fasta_file = outfolder / f\"{'_'.join(str(virus).split())}_sequences_combined.fasta\"\n",
        "        with open(combined_fasta_file, \"wb\") as outfh:\n",
        "            for src in [ncbi_fasta_file, Path(fasta_file)]:\n",
        "                with open(src, \"rb\") as fh:\n",
        "                    shutil.copyfileobj(fh, outfh)\n",
        "        input_fasta_file = combined_fasta_file\n",
        "\n",
        "        # Combine metadata\n",
        "        combined_metadata_file = outfolder / f\"{'_'.join(str(virus).split())}_metadata_combined.csv\"\n",
        "        ncbi_df = pd.read_csv(ncbi_metadata)\n",
        "\n",
        "        if 'metadata_csv' in globals() and metadata_csv:\n",
        "            user_meta_df = pd.read_csv(metadata_csv)\n",
        "            comb_meta_df = pd.concat([ncbi_df, user_meta_df], ignore_index=True, sort=False)\n",
        "            comb_meta_df.to_csv(combined_metadata_file, index=False)\n",
        "            metadata_file = combined_metadata_file\n",
        "        else:\n",
        "            # If user provided `metadata` mapping and FASTA only\n",
        "            headers = [record.id.split()[0] for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
        "            user_meta_df = pd.DataFrame({\"accession\": headers})\n",
        "            if 'metadata' in globals() and isinstance(metadata, dict):\n",
        "                for k, v in metadata.items():\n",
        "                    # Broadcast scalar values or accept list-like\n",
        "                    if hasattr(v, \"__len__\") and not isinstance(v, str) and len(v) == len(headers):\n",
        "                        user_meta_df[k] = v\n",
        "                    else:\n",
        "                        user_meta_df[k] = [v] * len(headers)\n",
        "            comb_meta_df = pd.concat([ncbi_df, user_meta_df], ignore_index=True, sort=False)\n",
        "            comb_meta_df.to_csv(combined_metadata_file, index=False)\n",
        "            metadata_file = combined_metadata_file\n",
        "\n",
        "        log_message_sub(f\"Merging complete. Combined FASTA: {combined_fasta_file.name}  Combined metadata: {combined_metadata_file.name}\")\n",
        "    except Exception as e:\n",
        "        log_message_error(\"Error while merging user-provided data.\")\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "# ---------- 3) Multiple Sequence Alignment (MSA) using MAFFT (Colab-friendly, --parttree for >10k) ----------\n",
        "log_message(\"3/5 Multiple Sequence Alignment (MAFFT). This may take time depending on # sequences and threads.\")\n",
        "\n",
        "aligned_fasta_file = outfolder / f\"{'_'.join(str(virus).split())}_aligned.afa\"\n",
        "\n",
        "def count_fasta_records(path: Path):\n",
        "    return sum(1 for _ in SeqIO.parse(str(path), \"fasta\"))\n",
        "\n",
        "# 1) Check for mafft binary\n",
        "def mafft_is_available():\n",
        "    return bool(shutil.which(\"mafft\"))\n",
        "\n",
        "# 2) If not available, attempt the same .deb download + dpkg approach you had for Colab\n",
        "if not mafft_is_available():\n",
        "    try:\n",
        "        log_message_sub(\"MAFFT not found ‚Äî attempting to download & install MAFFT .deb (Colab-compatible).\")\n",
        "        deb_path = outfolder / \"mafft_7.526-1_amd64.deb\"\n",
        "        # download\n",
        "        subprocess.run([\"wget\", \"-q\", \"-O\", str(deb_path),\n",
        "                        \"https://mafft.cbrc.jp/alignment/software/mafft_7.526-1_amd64.deb\"],\n",
        "                       check=True, text=True)\n",
        "        # install\n",
        "        subprocess.run([\"dpkg\", \"-i\", str(deb_path)], check=True, text=True)\n",
        "        # If dpkg left missing deps, try apt-get -f install\n",
        "        subprocess.run([\"apt-get\", \"-y\", \"install\", \"-f\"], check=True, text=True)\n",
        "        if mafft_is_available():\n",
        "            log_message_sub(\"MAFFT installed successfully.\")\n",
        "        else:\n",
        "            log_message_error(\"MAFFT was not found after .deb install. Please install MAFFT manually in the Colab environment.\")\n",
        "            raise FileNotFoundError(\"mafft binary not found after .deb install\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        log_message_error(\"An error occurred while attempting to install MAFFT via .deb.\")\n",
        "        # print stderr/stdout if available\n",
        "        try:\n",
        "            print(e.stderr or e.stdout)\n",
        "        except Exception:\n",
        "            print(e)\n",
        "        raise\n",
        "\n",
        "# 3) Prepare MAFFT command, adding --parttree for large datasets\n",
        "num_seqs = count_fasta_records(input_fasta_file)\n",
        "threads = int(threads) if 'threads' in globals() and threads else 1\n",
        "\n",
        "# Build command; place --parttree right after \"mafft\" (recommended)\n",
        "if num_seqs > 10_000:\n",
        "    log_message_sub(f\"Detected {num_seqs:,} sequences ‚Äî using MAFFT with --parttree optimized for large datasets.\")\n",
        "    mafft_cmd = [\"mafft\", \"--parttree\", \"--auto\", \"--thread\", str(threads), str(input_fasta_file)]\n",
        "else:\n",
        "    log_message_sub(f\"Detected {num_seqs:,} sequences ‚Äî using MAFFT standard --auto mode.\")\n",
        "    mafft_cmd = [\"mafft\", \"--auto\", \"--thread\", str(threads), str(input_fasta_file)]\n",
        "\n",
        "# 4) Run MAFFT and write alignment directly to file (no capture_output conflict)\n",
        "try:\n",
        "    log_message_sub(f\"Running: {' '.join(mafft_cmd[:6])} ... (command truncated in log)\")\n",
        "    with open(aligned_fasta_file, \"w\") as outfh:\n",
        "        # IMPORTANT: do NOT use capture_output=True here; provide stdout=outfh instead\n",
        "        subprocess.run(mafft_cmd, stdout=outfh, stderr=subprocess.PIPE, check=True, text=True)\n",
        "    log_message_sub(f\"MSA complete and saved to: {aligned_fasta_file.name}\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    log_message_error(\"Error while running MAFFT for MSA. See stderr below:\")\n",
        "    stderr = e.stderr.decode() if isinstance(e.stderr, (bytes, bytearray)) else e.stderr\n",
        "    print(stderr)\n",
        "    raise\n",
        "except Exception as e:\n",
        "    log_message_error(\"Unexpected error while running MAFFT.\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# ---------- 4) Reformat FASTA headers to match Delphy format (accession|YYYY-MM-DD) ----------\n",
        "log_message(\"4/5 Reformatting FASTA headers to 'accession|YYYY-MM-DD' (skipping entries without valid collection dates).\")\n",
        "\n",
        "def extract_and_format_date(date_string: str, accept_uncertain_dates: bool = False):\n",
        "    \"\"\"Return YYYY-MM-DD, YYYY-MM, or YYYY depending on accept_uncertain_dates. Return None if unrecognized.\"\"\"\n",
        "    if pd.isna(date_string):\n",
        "        return None\n",
        "    date_string = str(date_string).strip()\n",
        "    # Normalize separators to '-'\n",
        "    date_string = re.sub(r\"[/.]\", \"-\", date_string)\n",
        "    # Try parsing strict YYYY-MM-DD\n",
        "    full_date_re = re.compile(r\"^\\d{4}-\\d{1,2}-\\d{1,2}$\")\n",
        "    year_month_re = re.compile(r\"^\\d{4}-\\d{1,2}$\")\n",
        "    year_re = re.compile(r\"^\\d{4}$\")\n",
        "    if full_date_re.match(date_string):\n",
        "        return date_string\n",
        "    if year_month_re.match(date_string):\n",
        "        return date_string if accept_uncertain_dates else \"EXCLUDED\"\n",
        "    if year_re.match(date_string):\n",
        "        return date_string if accept_uncertain_dates else \"EXCLUDED\"\n",
        "    # Try to parse more flexible formats (e.g., 'Jan 2 2020' or '2 Jan 2020') using datetime\n",
        "    for fmt in (\"%Y-%m-%d\", \"%d-%b-%Y\", \"%d %b %Y\", \"%b %d %Y\", \"%Y/%m/%d\"):\n",
        "        try:\n",
        "            dt = datetime.strptime(date_string, fmt)\n",
        "            return dt.strftime(\"%Y-%m-%d\")\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def find_date_columns(df: pd.DataFrame):\n",
        "    \"\"\"Heuristic to find which column likely contains collection date and accession.\"\"\"\n",
        "    date_cols = [c for c in df.columns if re.search(r\"date|collection|collected\", c, flags=re.I)]\n",
        "    acc_cols = [c for c in df.columns if re.search(r\"acc(?:ession)?|id|seq_id\", c, flags=re.I)]\n",
        "    # Fallback sensible names\n",
        "    if not date_cols and \"Collection Date\" in df.columns:\n",
        "        date_cols = [\"Collection Date\"]\n",
        "    if not acc_cols and \"accession\" in df.columns:\n",
        "        acc_cols = [\"accession\"]\n",
        "    # Return first hits or None\n",
        "    return (date_cols[0] if date_cols else None, acc_cols[0] if acc_cols else None)\n",
        "\n",
        "def update_fasta_headers(fasta_in: Path, csv_in: Path, fasta_out: Path, accept_uncertain_dates: bool = False):\n",
        "    \"\"\"Rewrite fasta headers to 'accession|date' using CSV metadata. Exclude entries without valid date.\"\"\"\n",
        "    df = pd.read_csv(csv_in, dtype=str)\n",
        "    date_col, acc_col = find_date_columns(df)\n",
        "    if date_col is None or acc_col is None:\n",
        "        raise ValueError(f\"Could not find accession/date columns in {csv_in}. Found columns: {list(df.columns)}\")\n",
        "    accession_to_date = pd.Series(df[date_col].values, index=df[acc_col]).to_dict()\n",
        "\n",
        "    included = 0\n",
        "    excluded = 0\n",
        "    unrecognized = 0\n",
        "\n",
        "    with open(fasta_in) as fh_in, open(fasta_out, \"w\") as fh_out:\n",
        "        for record in SeqIO.parse(fh_in, \"fasta\"):\n",
        "            original_accession = record.id.split()[0]\n",
        "            date_val = accession_to_date.get(original_accession) or accession_to_date.get(original_accession.split(\"|\")[0])\n",
        "            formatted = extract_and_format_date(date_val, accept_uncertain_dates=accept_uncertain_dates)\n",
        "            if formatted == \"EXCLUDED\":\n",
        "                excluded += 1\n",
        "                continue\n",
        "            if formatted is None:\n",
        "                unrecognized += 1\n",
        "                continue\n",
        "            # Set header and remove description\n",
        "            record.id = f\"{original_accession}|{formatted}\"\n",
        "            record.description = \"\"\n",
        "            SeqIO.write(record, fh_out, \"fasta\")\n",
        "            included += 1\n",
        "\n",
        "    return {\"included\": included, \"excluded\": excluded, \"unrecognized\": unrecognized}\n",
        "\n",
        "aligned_fasta_file_clean = outfolder / f\"{'_'.join(str(virus).split())}_aligned_headers_adjusted.afa\"\n",
        "try:\n",
        "    accept_uncertain_dates = bool(globals().get(\"accept_uncertain_dates\", False))\n",
        "    stats = update_fasta_headers(aligned_fasta_file, metadata_file, aligned_fasta_file_clean, accept_uncertain_dates=accept_uncertain_dates)\n",
        "    log_message_sub(f\"Reformatting complete. Included {stats['included']} sequences; excluded (incomplete dates) {stats['excluded']}; unrecognized {stats['unrecognized']}\")\n",
        "except Exception as e:\n",
        "    log_message_error(\"Error while reformatting FASTA headers.\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# ---------- 5) Run Delphy ----------\n",
        "log_message(\"5/5 Preparing and running Delphy. This step can be long depending on steps/samples/sequence count.\")\n",
        "\n",
        "def count_fasta_records(path: Path):\n",
        "    return sum(1 for _ in SeqIO.parse(str(path), \"fasta\"))\n",
        "\n",
        "num_seqs = count_fasta_records(aligned_fasta_file_clean)\n",
        "if num_seqs == 0:\n",
        "    raise RuntimeError(f\"No sequences found in {aligned_fasta_file_clean}\")\n",
        "\n",
        "# sensible defaults for delphy params if not provided\n",
        "delphy_steps = globals().get(\"delphy_steps\")\n",
        "delphy_samples = globals().get(\"delphy_samples\", 100)\n",
        "if delphy_steps is None:\n",
        "    delphy_steps = int(500_000 * max(1, num_seqs))\n",
        "\n",
        "log_every = int(delphy_steps / delphy_samples) if delphy_samples else max(1, delphy_steps // 100)\n",
        "tree_every = log_every\n",
        "delphy_snapshot_every = log_every\n",
        "\n",
        "# Download delphy if not present\n",
        "delphy_bin = (Path.cwd() / \"delphy\").resolve()\n",
        "if not delphy_bin.exists():\n",
        "    delphy_release = globals().get(\"delphy_release\", \"1.2.2\")  # user may override\n",
        "    tarball = outfolder / \"delphy_release.tar.gz\"\n",
        "    try:\n",
        "        download_url = f\"https://github.com/broadinstitute/delphy/releases/download/{delphy_release}/delphy-linux-x86_64-ubuntu22.tar.gz\"\n",
        "        log_message_sub(f\"Downloading Delphy release {delphy_release}.\")\n",
        "        run_checked([\"wget\", \"-q\", \"-O\", str(tarball), download_url])\n",
        "        run_checked([\"tar\", \"-xzf\", str(tarball)], check=True)\n",
        "        # Try to find delphy binary in extracted files\n",
        "        found = list(Path(\".\").glob(\"**/delphy\"))\n",
        "        if found:\n",
        "            src = found[0].resolve()\n",
        "            dst = delphy_bin.resolve()\n",
        "\n",
        "            # Make sure the found binary is executable\n",
        "            src.chmod(src.stat().st_mode | 0o111)\n",
        "\n",
        "            # Only copy if it's not already the same file\n",
        "            if src != dst:\n",
        "                shutil.copy(src, dst)\n",
        "                dst.chmod(dst.stat().st_mode | 0o111)\n",
        "                log_message_sub(\"Delphy binary obtained.\")\n",
        "            else:\n",
        "                log_message_sub(\"Delphy binary already present in working directory; skipping copy.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log_message_error(\"Failed to download/extract Delphy. Please ensure `delphy` binary is available in the working directory.\")\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "# Build Delphy command\n",
        "beast_log_out = outfolder / f\"{'_'.join(str(virus).split())}_delphy_beast.log\"\n",
        "delphy_beast_tree_out = outfolder / f\"{'_'.join(str(virus).split())}_delphy_beast.trees\"\n",
        "dphy_out = outfolder / f\"{'_'.join(str(virus).split())}_delphy_out.dphy\"\n",
        "\n",
        "mutation_rate = globals().get(\"mutation_rate\", None)\n",
        "threads = int(globals().get(\"threads\", 1))\n",
        "cmd = [\n",
        "    str(delphy_bin),\n",
        "    \"--v0-log-every\", str(log_every),\n",
        "    \"--v0-tree-every\", str(tree_every),\n",
        "    \"--v0-delphy-snapshot-every\", str(delphy_snapshot_every),\n",
        "    \"--v0-threads\", str(threads),\n",
        "    \"--v0-steps\", str(delphy_steps),\n",
        "    \"--v0-in-fasta\", str(aligned_fasta_file_clean),\n",
        "    \"--v0-out-log-file\", str(beast_log_out),\n",
        "    \"--v0-out-trees-file\", str(delphy_beast_tree_out),\n",
        "    \"--v0-out-delphy-file\", str(dphy_out),\n",
        "]\n",
        "if mutation_rate:\n",
        "    cmd = [str(delphy_bin), \"--v0-fix-mutation-rate\", \"--v0-init-mutation-rate\", str(mutation_rate)] + cmd[1:]\n",
        "\n",
        "log_message_sub(f\"Running Delphy with command: {' '.join(cmd[:8])} ... (truncated)\")\n",
        "\n",
        "try:\n",
        "    # Run delphy and stream output to notebook\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "    for line in proc.stdout:\n",
        "        # print lines incrementally so the notebook shows progress\n",
        "        print(line, end=\"\")\n",
        "    ret = proc.wait()\n",
        "    if ret != 0:\n",
        "        raise subprocess.CalledProcessError(ret, cmd)\n",
        "    # Success\n",
        "    display(HTML(\"\"\"\n",
        "    <h2 style='color:green'>All done! üéâ</h2>\n",
        "    <p>Files generated in this notebook are in the left-hand file browser (or in the folder you set as <code>outfolder</code>).</p>\n",
        "    <ul>\n",
        "      <li>Aligned FASTA: <code>{}</code></li>\n",
        "      <li>Delphy output (.dphy): <code>{}</code></li>\n",
        "      <li>Delphy log (.log): <code>{}</code></li>\n",
        "      <li>Delphy trees (.trees): <code>{}</code></li>\n",
        "    </ul>\n",
        "    <p>We recommend downloading the <code>.afa</code>, <code>.dphy</code>, and <code>metadata.csv</code> files. To visualize .dphy files online, try <a href='https://delphy.fathom.info/' target='_blank'>delphy.fathom.info</a>.</p>\n",
        "    \"\"\".format(aligned_fasta_file_clean.name, dphy_out.name, beast_log_out.name, delphy_beast_tree_out.name)))\n",
        "except subprocess.CalledProcessError as e:\n",
        "    log_message_error(\"An error occurred while running Delphy. See captured output above for details.\")\n",
        "    print(e)\n",
        "    raise\n",
        "except Exception as e:\n",
        "    log_message_error(\"Unexpected error while running Delphy.\")\n",
        "    print(e)\n",
        "    raise\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HuVr7cb0x5VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdHHacImXoDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
